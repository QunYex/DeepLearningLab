{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Input\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras.backend as K\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "MEAN_PIXEL = np.array([103.939, 116.779, 123.68])\n",
    "\n",
    "WEIGHTS_PATH = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                        WEIGHTS_PATH_NO_TOP,\n",
    "                        cache_subdir='models',\n",
    "                        file_hash='253f8cb515780f3b799900260a226db6')\n",
    "\n",
    "def vgg_layers(inputs, target_layer):\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "    if target_layer == 1:\n",
    "        return x\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    if target_layer == 2:\n",
    "        return x\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    if target_layer == 3:\n",
    "        return x\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    if target_layer == 4:\n",
    "        return x\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_weights(model):\n",
    "    f = h5py.File(WEIGHTS_PATH)\n",
    "    layer_names = [name for name in f.attrs['layer_names']]\n",
    "\n",
    "    for layer in model.layers:\n",
    "        b_name = layer.name.encode()\n",
    "        if b_name in layer_names:\n",
    "            g = f[b_name]\n",
    "            weights = [g[name] for name in g.attrs['weight_names']]\n",
    "            layer.set_weights(weights)\n",
    "            layer.trainable = False\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def VGG19(input_tensor=None, input_shape=None, target_layer=1):\n",
    "    \"\"\"\n",
    "    VGG19, up to the target layer (1 for relu1_1, 2 for relu2_1, etc.)\n",
    "    \"\"\"\n",
    "    if input_tensor is None:\n",
    "        inputs = Input(shape=input_shape)\n",
    "    else:\n",
    "        inputs = Input(tensor=input_tensor, shape=input_shape)\n",
    "    model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19')\n",
    "    load_weights(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    # Convert 'RGB' -> 'BGR'\n",
    "    if type(x) is np.ndarray:\n",
    "        x = x[..., ::-1]\n",
    "    else:\n",
    "        x = tf.reverse(x, [-1])\n",
    "\n",
    "    return x - MEAN_PIXEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image/elephant.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-23956dd9570d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mimg_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image/elephant.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mimg_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mimg_c_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image/elephant.png'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def get_vgg_features(vgg, inputs, target_layer):\n",
    "    output_layers = [\n",
    "            'block1_conv1',\n",
    "            'block2_conv1',\n",
    "            'block3_conv1',\n",
    "            'block4_conv1',\n",
    "            'block5_conv1'\n",
    "    ]\n",
    "\n",
    "    outputs = [layer.output for layer in vgg.layers\n",
    "               if layer.name == output_layers[target_layer-1]]\n",
    "    f = K.function([vgg.input] + [K.learning_phase()], outputs)\n",
    "    return f([inputs, 1.])\n",
    "\n",
    "\n",
    "def wct(content, style, alpha=0.6, eps=1e-5):\n",
    "    '''\n",
    "    https://github.com/eridgd/WCT-TF/blob/master/ops.py\n",
    "\n",
    "       Perform Whiten-Color Transform on feature maps using numpy\n",
    "       See p.4 of the Universal Style Transfer paper for equations:\n",
    "       https://arxiv.org/pdf/1705.08086.pdf\n",
    "    '''\n",
    "    # 1xHxWxC -> CxHxW\n",
    "    content_t = np.transpose(np.squeeze(content), (2, 0, 1))\n",
    "    style_t = np.transpose(np.squeeze(style), (2, 0, 1))\n",
    "\n",
    "    # CxHxW -> CxH*W\n",
    "    content_flat = content_t.reshape(-1, content_t.shape[1]*content_t.shape[2])\n",
    "    style_flat = style_t.reshape(-1, style_t.shape[1]*style_t.shape[2])\n",
    "\n",
    "    # Whitening transform\n",
    "    mc = content_flat.mean(axis=1, keepdims=True)\n",
    "    fc = content_flat - mc\n",
    "    fcfc = np.dot(fc, fc.T) / (content_t.shape[1]*content_t.shape[2] - 1)\n",
    "    Ec, wc, _ = np.linalg.svd(fcfc)\n",
    "    k_c = (wc > 1e-5).sum()\n",
    "    Dc = np.diag((wc[:k_c]+eps)**-0.5)\n",
    "    fc_hat = Ec[:,:k_c].dot(Dc).dot(Ec[:,:k_c].T).dot(fc)\n",
    "\n",
    "    # Coloring transform\n",
    "    ms = style_flat.mean(axis=1, keepdims=True)\n",
    "    fs = style_flat - ms\n",
    "    fsfs = np.dot(fs, fs.T) / (style_t.shape[1]*style_t.shape[2] - 1)\n",
    "    Es, ws, _ = np.linalg.svd(fsfs)\n",
    "    k_s = (ws > 1e-5).sum()\n",
    "    Ds = np.sqrt(np.diag(ws[:k_s]+eps))\n",
    "    fcs_hat = Es[:,:k_s].dot(Ds).dot(Es[:,:k_s].T).dot(fc_hat)\n",
    "    fcs_hat = fcs_hat + ms\n",
    "\n",
    "    # Blend transform features with original features\n",
    "    blended = alpha*fcs_hat + (1 - alpha)*(fc)\n",
    "\n",
    "    # CxH*W -> CxHxW\n",
    "    blended = blended.reshape(content_t.shape)\n",
    "    # CxHxW -> 1xHxWxC\n",
    "    blended = np.expand_dims(np.transpose(blended, (1,2,0)), 0)\n",
    "\n",
    "    return np.float32(blended)\n",
    "\n",
    "\n",
    "\n",
    "img_c = image.load_img(\"image/elephant.png\")\n",
    "img_c = image.img_to_array(img_c)\n",
    "img_c_shape = img_c.shape\n",
    "img_c = np.expand_dims(img_c, axis=0)\n",
    "\n",
    "img_s = image.load_img(\"image/star.jpg\")\n",
    "img_s = image.img_to_array(img_s)\n",
    "img_s_shape = img_s.shape\n",
    "img_s = np.expand_dims(img_s, axis=0)\n",
    "\n",
    "assert img_c_shape == img_s_shape, \\\n",
    "    'Content and style image should be the same shape, %s != %s' \\\n",
    "    % (str(img_c_shape), str(img_s_shape))\n",
    "\n",
    "input_shape = img_c_shape\n",
    "\n",
    "print('Loading decoders...')\n",
    "decoders = {}\n",
    "decoders[1] = load_model('./models/decoder_1.h5')\n",
    "decoders[2] = load_model('./models/decoder_2.h5')\n",
    "decoders[3] = load_model('./models/decoder_3.h5')\n",
    "decoders[4] = load_model('./models/decoder_4.h5')\n",
    "decoders[5] = load_model('./models/decoder_5.h5')\n",
    "\n",
    "print('Loading VGG...')\n",
    "vgg = VGG19(input_shape=input_shape, target_layer=5)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(np.clip(img_c[0] / 255, 0, 1))\n",
    "plt.show()\n",
    "\n",
    "print('Styling...')\n",
    "for i in [3, 1]:\n",
    "    feats_c = get_vgg_features(vgg, img_c, i)\n",
    "    feats_s = get_vgg_features(vgg, img_s, i)\n",
    "    feats_cs = wct(feats_c, feats_s)\n",
    "    img_c = decoders[i].predict(feats_cs)\n",
    "    plt.imshow(np.clip(img_c[0] / 255, 0, 1))\n",
    "    plt.show()\n",
    "\n",
    "print('Saving output...')\n",
    "output_img = img_c[0]\n",
    "\n",
    "#imsave(sys.argv[3], output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
