{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#Directly Load Model\n",
    "from pathlib import PurePath\n",
    "import tensorflow as tf\n",
    "ModelBlock5 = tf.keras.models.load_model(str(PurePath('Model','Block5_Model')), compile = False)\n",
    "\n",
    "Image_sample = tf.zeros([384,384,3])\n",
    "#Make it 4D Tensor\n",
    "Image_sample_input = tf.expand_dims(Image_sample, 0)\n",
    "Out_image = ModelBlock5(Image_sample_input)\n",
    "print(Out_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### !/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from pathlib import PurePath\n",
    "import sys\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class VGG19AE(tf.keras.Model):\n",
    "    def __init__(self, files_path):\n",
    "        super(VGG19AE, self).__init__()\n",
    "        #Load Model\n",
    "        ModelBlock5 = tf.keras.models.load_model(str(PurePath(files_path, 'Block5_Model')), compile = False)\n",
    "        #Get Each SubModel\n",
    "        self.E5 = ModelBlock5.layers[0]\n",
    "        self.D5 = ModelBlock5.layers[1]\n",
    "        self.O5 = ModelBlock5.layers[2]\n",
    "        ModelBlock4 = tf.keras.models.load_model(str(PurePath(files_path, 'Block4_Model')), compile = False)\n",
    "        self.E4 = ModelBlock4.layers[0]\n",
    "        self.D4 = ModelBlock4.layers[1]\n",
    "        self.O4 = ModelBlock4.layers[2]\n",
    "        ModelBlock3 = tf.keras.models.load_model(str(PurePath(files_path, 'Block3_Model')), compile = False)\n",
    "        self.E3 = ModelBlock3.layers[0]\n",
    "        self.D3 = ModelBlock3.layers[1]\n",
    "        self.O3 = ModelBlock3.layers[2]\n",
    "        ModelBlock2 = tf.keras.models.load_model(str(PurePath(files_path, 'Block2_Model')), compile = False)\n",
    "        self.E2 = ModelBlock2.layers[0]\n",
    "        self.D2 = ModelBlock2.layers[1]\n",
    "        self.O2 = ModelBlock2.layers[2]\n",
    "        ModelBlock1 = tf.keras.models.load_model(str(PurePath(files_path, 'Block1_Model')), compile = False)\n",
    "        self.E1 = ModelBlock1.layers[0]\n",
    "        self.O1 = ModelBlock1.layers[1]\n",
    "\n",
    "    def call(self, Image, training  = False):\n",
    "        # Input should be 4D Tensor\n",
    "        xo, I2 = Image\n",
    "        x = self.E4(xo)\n",
    "        style = self.E4(I2)\n",
    "        #Add WCT Here\n",
    "        #x = wct(x,style)\n",
    "        # x = self.wct(self,x,style)\n",
    "        x = self.D5(x)\n",
    "        x = self.O5(x)\n",
    "        # Block 1 Donot have decoder because it don't contain Pooling and there are only one Conv layer.\n",
    "        x = self.E1(x)\n",
    "        x = self.O1(x)\n",
    "        return tf.clip_by_value(tf.squeeze(x), 0, 1)\n",
    "AE = VGG19AE('Model')\n",
    "\n",
    "\n",
    "img_c = image.load_img(\"image/elephant.jpeg\")\n",
    "#img = tf.image.resize(img_c,(400,400))\n",
    "img_c = image.img_to_array(img_c)\n",
    "img_c_shape = img_c.shape\n",
    "\n",
    "\n",
    "img_s = image.load_img(\"image/target.jpg\")\n",
    "img_s = image.img_to_array(img_s)\n",
    "img_s_shape = img_s.shape\n",
    "\n",
    "\n",
    "\n",
    "#Make it 4D Tensor\n",
    "Image_sample_input = (tf.expand_dims(img_c, 0), tf.expand_dims(img_s, 0))\n",
    "Out_image = AE(Image_sample_input)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(Out_image)\n",
    "plt.show()\n",
    "\n",
    "#print(Out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wct(content, style, alpha=0.6, eps=1e-5):\n",
    "    '''\n",
    "    https://github.com/eridgd/WCT-TF/blob/master/ops.py\n",
    "       Perform Whiten-Color Transform on feature maps using numpy\n",
    "       See p.4 of the Universal Style Transfer paper for equations:\n",
    "       https://arxiv.org/pdf/1705.08086.pdf\n",
    "    '''\n",
    "    # 1xHxWxC -> CxHxW\n",
    "    content_t = np.transpose(np.squeeze(content), (2, 0, 1))\n",
    "    style_t = np.transpose(np.squeeze(style), (2, 0, 1))\n",
    "\n",
    "    # CxHxW -> CxH*W\n",
    "    content_flat = content_t.reshape(-1, content_t.shape[1]*content_t.shape[2])\n",
    "    style_flat = style_t.reshape(-1, style_t.shape[1]*style_t.shape[2])\n",
    "\n",
    "    # Whitening transform\n",
    "    mc = content_flat.mean(axis=1, keepdims=True)\n",
    "    fc = content_flat - mc\n",
    "    fcfc = np.dot(fc, fc.T) / (content_t.shape[1]*content_t.shape[2] - 1)\n",
    "    Ec, wc, _ = np.linalg.svd(fcfc)\n",
    "    k_c = (wc > 1e-5).sum()\n",
    "    Dc = np.diag((wc[:k_c]+eps)**-0.5)\n",
    "    fc_hat = Ec[:,:k_c].dot(Dc).dot(Ec[:,:k_c].T).dot(fc)\n",
    "\n",
    "    # Coloring transform\n",
    "    ms = style_flat.mean(axis=1, keepdims=True)\n",
    "    fs = style_flat - ms\n",
    "    fsfs = np.dot(fs, fs.T) / (style_t.shape[1]*style_t.shape[2] - 1)\n",
    "    Es, ws, _ = np.linalg.svd(fsfs)\n",
    "    k_s = (ws > 1e-5).sum()\n",
    "    Ds = np.sqrt(np.diag(ws[:k_s]+eps))\n",
    "    fcs_hat = Es[:,:k_s].dot(Ds).dot(Es[:,:k_s].T).dot(fc_hat)\n",
    "    fcs_hat = fcs_hat + ms\n",
    "\n",
    "    # Blend transform features with original features\n",
    "    blended = alpha*fcs_hat + (1 - alpha)*(fc)\n",
    "\n",
    "    # CxH*W -> CxHxW\n",
    "    blended = blended.reshape(content_t.shape)\n",
    "    # CxHxW -> 1xHxWxC\n",
    "    blended = np.expand_dims(np.transpose(blended, (1,2,0)), 0)\n",
    "\n",
    "    return np.float32(blended)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
